{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# nltk sentiment analysis\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# textblob sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "data_path = \"~/Desktop/NewsGenerator/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load all data into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(data_path+\"articles1.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df2 = pd.read_csv(data_path+\"articles2.csv\").drop(\"Unnamed: 0\", axis=1)\n",
    "df3 = pd.read_csv(data_path+\"articles3.csv\").drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 142570 entries, 0 to 42570\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           142570 non-null  int64  \n",
      " 1   title        142568 non-null  object \n",
      " 2   publication  142570 non-null  object \n",
      " 3   author       126694 non-null  object \n",
      " 4   date         139929 non-null  object \n",
      " 5   year         139929 non-null  float64\n",
      " 6   month        139929 non-null  float64\n",
      " 7   url          85559 non-null   object \n",
      " 8   content      142570 non-null  object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 10.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Publications\n",
    "\n",
    "we first need to figure out what types of articles are there. So, we can print the unique names of publications and how to define the project better. A couple rudimentary analysis is done to get basic statistics like counts of publications, and how I've divided up the publications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Atlantic', 'Breitbart', 'Business Insider', 'Buzzfeed News',\n",
       "       'CNN', 'Fox News', 'Guardian', 'NPR', 'National Review',\n",
       "       'New York Post', 'New York Times', 'Reuters',\n",
       "       'Talking Points Memo', 'Vox', 'Washington Post'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubs = np.unique(df.publication)\n",
    "pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlantic\n",
      "\tNumber of Articles: 7179\n",
      "\tFraction of the dataset: 5.04\n",
      "Breitbart\n",
      "\tNumber of Articles: 23781\n",
      "\tFraction of the dataset: 16.68\n",
      "Business Insider\n",
      "\tNumber of Articles: 6757\n",
      "\tFraction of the dataset: 4.74\n",
      "Buzzfeed News\n",
      "\tNumber of Articles: 4854\n",
      "\tFraction of the dataset: 3.4\n",
      "CNN\n",
      "\tNumber of Articles: 11488\n",
      "\tFraction of the dataset: 8.06\n",
      "Fox News\n",
      "\tNumber of Articles: 4354\n",
      "\tFraction of the dataset: 3.05\n",
      "Guardian\n",
      "\tNumber of Articles: 8681\n",
      "\tFraction of the dataset: 6.09\n",
      "NPR\n",
      "\tNumber of Articles: 11992\n",
      "\tFraction of the dataset: 8.41\n",
      "National Review\n",
      "\tNumber of Articles: 6203\n",
      "\tFraction of the dataset: 4.35\n",
      "New York Post\n",
      "\tNumber of Articles: 17493\n",
      "\tFraction of the dataset: 12.27\n",
      "New York Times\n",
      "\tNumber of Articles: 7803\n",
      "\tFraction of the dataset: 5.47\n",
      "Reuters\n",
      "\tNumber of Articles: 10710\n",
      "\tFraction of the dataset: 7.51\n",
      "Talking Points Memo\n",
      "\tNumber of Articles: 5214\n",
      "\tFraction of the dataset: 3.66\n",
      "Vox\n",
      "\tNumber of Articles: 4947\n",
      "\tFraction of the dataset: 3.47\n",
      "Washington Post\n",
      "\tNumber of Articles: 11114\n",
      "\tFraction of the dataset: 7.8\n"
     ]
    }
   ],
   "source": [
    "total_count = 142570\n",
    "for x in pubs:\n",
    "    print(x)\n",
    "    n = df[df.publication == x].shape[0]\n",
    "    print(\"\\tNumber of Articles:\",n)\n",
    "    print(\"\\tFraction of the dataset:\",round(n/total_count*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23781"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.publication == \"Breitbart\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4354"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.publication == \"Fox News\"].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first take a look at NYT article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rift Between Officers and Residents as Killings Persist in South Bronx - The New York Times'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                         17284\n",
       "title          Rift Between Officers and Residents as Killing...\n",
       "publication                                       New York Times\n",
       "author                             Benjamin Mueller and Al Baker\n",
       "date                                                  2017-06-19\n",
       "year                                                        2017\n",
       "month                                                          6\n",
       "url                                                          NaN\n",
       "content        After the bullet shells get counted, the blood...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt = df.iloc[1]\n",
    "nyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.157, 'neu': 0.784, 'pos': 0.059, 'compound': -1.0}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(nyt.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take a look at a random Breitbart article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Watch: Spicer Asked How It Feels ’To Work for a Fascist?’ In Apple Store - Breitbart'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[10001].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                         28737\n",
       "title          Watch: Spicer Asked How It Feels ’To Work for ...\n",
       "publication                                            Breitbart\n",
       "author                                              Ian Hanchett\n",
       "date                                                  2017-03-12\n",
       "year                                                        2017\n",
       "month                                                          3\n",
       "url                                                          NaN\n",
       "content        Asking @PressSec questions in Apple Store sinc...\n",
       "Name: 10001, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = df.iloc[10001]\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.156, 'neu': 0.755, 'pos': 0.089, 'compound': -0.9282}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(bb.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite such a different content and political polemics, the sentiment actually doesn't seem to have changed all that much.  Mostly, the articles both point to neutral.\n",
    "\n",
    "What if we wanted to use a different sentiment analysis tool?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
